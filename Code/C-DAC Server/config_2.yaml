dataset_name: "sentence-transformers/natural-questions"
dataset_split: "train[:1000]"
dataset_path: "sentence-transformers/natural-questions"

phi_model: "microsoft/phi-2"  # Hugging Face path for Phi-2
pythia_model: "EleutherAI/pythia-1b"  # Hugging Face path for Pythia-1B
refiner_model: "meta-llama/Llama-3.2-1B-Instruct"  # Updated to correct HF path (assuming you meant 8B instruct)
embedder_model: "sentence-transformers/all-MiniLM-L6-v2"  # Hugging Face path for embedder

max_new_tokens: 100
temperature: 0.7
top_k: 50
top_p: 0.9
repetition_penalty: 1.2
