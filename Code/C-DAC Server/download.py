# -*- coding: utf-8 -*-
"""download.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IrSQciR2mOXqBNK-KvejY5WQAtS_yMXj
"""

from transformers import AutoTokenizer, AutoModelForCausalLM
from sentence_transformers import SentenceTransformer
from datasets import load_dataset
import evaluate
import os


BASE_DIR = "/nlsasfs/home/neol/konad/partha/models"
os.makedirs(BASE_DIR, exist_ok=True)

def save_transformer_model(model_name):
    print(f"Downloading: {model_name}")
    path = f"{BASE_DIR}/{model_name.replace('/', '_')}"
    AutoTokenizer.from_pretrained(model_name).save_pretrained(path)
    AutoModelForCausalLM.from_pretrained(model_name).save_pretrained(path)

def save_sentence_transformer(model_name):
    print(f"Downloading embedder: {model_name}")
    SentenceTransformer(model_name, cache_folder=BASE_DIR)

def save_dataset(name, split="train[:1000]"):
    print(f"Downloading dataset: {name}")
    load_dataset(name, split=split, cache_dir=BASE_DIR)

def save_metrics():
    print("Downloading evaluation metrics...")
    evaluate.load("bleu", cache_dir=BASE_DIR)
    evaluate.load("bertscore", cache_dir=BASE_DIR)

if __name__ == "__main__":
    save_transformer_model("microsoft/phi-2")
    save_transformer_model("EleutherAI/pythia-1b")
    save_transformer_model("meta-llama/Llama-3.2-1B-Instruct")
    save_sentence_transformer("sentence-transformers/all-MiniLM-L6-v2")
    save_dataset("sentence-transformers/natural-questions", split="train[:1000]")
    save_metrics()
    print("\nâœ… All models and data downloaded to /nlsasfs/home/neol/konad/partha/models")
